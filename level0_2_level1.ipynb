{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "__author__ = \"zeshi\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from mysqldb_level0 import query_data_level0, site_info_check\n",
    "import mysql.connector\n",
    "from mysql.connector.pooling import MySQLConnectionPool\n",
    "from mysql.connector import errorcode\n",
    "from datetime import datetime, date, timedelta\n",
    "from multiprocessing import Pool, cpu_count\n",
    "from functools import partial\n",
    "\n",
    "# Define all querie in this database\n",
    "site_id_query = (\"SELECT site_id, num_of_nodes FROM sites WHERE site_name = %s\")\n",
    "level1_time_query = (\"SELECT sd_level_1, server_level_1 FROM motes WHERE site_id = %s AND node_id = %s\")\n",
    "level0_time_query = (\"SELECT sd_last_update, server_last_update FROM motes WHERE site_id = %s \" \n",
    "                     \"AND node_id = %s\")\n",
    "level1_insert_string = (\"INSERT INTO level_1 \"\n",
    "                        \"(site_id, node_id, datetime, voltage, temperature, relative_humidity, \"\n",
    "                        \"soil_moisture_1, soil_temperature_1, soil_ec_1, soil_moisture_2, \"\n",
    "                        \"soil_temperature_2, soil_ec_2, snowdepth, judd_temp, solar, maxibotics, sd_card) \"\n",
    "                        \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "level1_sd_time_update = (\"UPDATE motes SET sd_level_1 = %s WHERE site_id = %s AND node_id = %s\")\n",
    "level1_server_time_update = (\"UPDATE motes SET server_level_1 = %s WHERE site_id = %s AND node_id = %s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def formater(data_row):\n",
    "    output = ()\n",
    "    for i, item in enumerate(data_row):\n",
    "        if i != 14 and i != 15:\n",
    "            output = output + (item, )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_site_id(site_name, cursor):\n",
    "    try:\n",
    "        cursor.execute(site_id_query, (site_name, ))\n",
    "        site_id = cursor.fetchall()[0][0]\n",
    "        return site_id\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "        return None\n",
    "    except IndexError as err:\n",
    "        print(err)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_time(site_id, node_id, time_query_string, cursor):\n",
    "    try:\n",
    "        cursor.execute(time_query_string, (site_id, node_id))\n",
    "        time = cursor.fetchall()[0]\n",
    "        return time\n",
    "    except IndexError as err:\n",
    "        print(\"The node_id is wrong!\")\n",
    "        return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def level0_to_level1_time(site_name, node_id, pool_bool=False):\n",
    "    \"\"\"\n",
    "    This function return the maximum time range to update the level1 table from level0 table\n",
    "    :param: site_name:          string, site name\n",
    "    :param node_id:             int, node id\n",
    "    \"\"\"\n",
    "    if pool_bool:\n",
    "        cnx = pool.get_connection()\n",
    "    else:\n",
    "        cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    site_id = query_site_id(site_name, cursor)\n",
    "    if site_id is None:\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        print(site_name + \"is not a valid site name!\")\n",
    "        return (None, None, None)\n",
    "    sd_last_update, server_last_update = query_time(site_id, node_id, level0_time_query, cursor)\n",
    "    if sd_last_update is None and server_last_update is None:\n",
    "        print(site_name + \": node_\" + str(node_id) + \" has not been updated for level_0 data yet \" + \n",
    "              \"or node_id is wrong\")\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return (None, None, None)\n",
    "    else:\n",
    "        if sd_last_update is None:\n",
    "            ending_datetime = server_last_update\n",
    "        elif server_last_update is None:\n",
    "            ending_datetime = sd_last_update\n",
    "        else:\n",
    "            if sd_last_update > server_last_update:\n",
    "                ending_datetime = sd_last_update\n",
    "            else:\n",
    "                ending_datetime = server_last_update\n",
    "    sd_level_1, server_level_1 = query_time(site_id, node_id, level1_time_query, cursor)\n",
    "    if sd_level_1 > server_level_1:\n",
    "        starting_datetime = server_level_1\n",
    "    else:\n",
    "        starting_datetime = sd_level_1\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "    return (site_id, starting_datetime, ending_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_data_level1(site_name_id, node_id, row_datetime, new_row, pool_bool=False):\n",
    "    \"\"\"\n",
    "    Update level1 data from mysql database\n",
    "    :param site_name_id:        int or string, The site name or site id of the data\n",
    "    :param node_id:             int, node id\n",
    "    :param row_datetime         datetime, the datetime of the row we are going to update\n",
    "    :param new_row              tuple, the new data row to replace the old row\n",
    "    \"\"\"\n",
    "    # Check if site_name_id and node_id valid\n",
    "    try:\n",
    "        site_id = site_info_check(site_name_id, node_id)\n",
    "    except ValueError as err:\n",
    "        print(\"Could not update row because of invalid site name/id and node id!\")\n",
    "        return\n",
    "        \n",
    "    # Define query string\n",
    "    level1_update_query = (\"UPDATE level_1 SET voltage = %s, \"\n",
    "                           \"temperature = %s, relative_humidity = %s, soil_moisture_1 = %s, \"\n",
    "                           \"soil_temperature_1 = %s, soil_ec_1 = %s, soil_moisture_2 = %s, soil_temperature_2 = %s, \"\n",
    "                           \"soil_ec_2 = %s, snowdepth = %s, judd_temp = %s, solar = %s, \"\n",
    "                           \"maxibotics = %s, sd_card = %s WHERE site_id = %s AND node_id = %s AND datetime = %s\")\n",
    "    exec_data = ()\n",
    "    for i in range(3, 17):\n",
    "        exec_data = exec_data + (new_row[i], )\n",
    "    for i in range(0, 3):\n",
    "        exec_data = exec_data + (new_row[i], )\n",
    "    if pool_bool:\n",
    "        cnx = pool.get_connection()\n",
    "    else:\n",
    "        cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    try:\n",
    "        cursor.execute(level1_update_query, exec_data)\n",
    "        cnx.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Update failed because of mysql error!\")\n",
    "        print(err)\n",
    "    cursor.close()\n",
    "    cnx.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_data_level1(site_name_id, node_id, starting_datetime, ending_datetime, field = None):\n",
    "    \"\"\"\n",
    "    Query level1 data from mysql database\n",
    "    :param site_name_id:        int or string, The site name or site id of the data\n",
    "    :param node_id:             int, node id\n",
    "    :param starting_datetime:   datetime, starting datetime of query\n",
    "    :param ending_datetime:     datetime, ending datetime of query\n",
    "    :param field:               string, name of the field to be queried\n",
    "    :return:                    tuple, data rows that queried from the database\n",
    "    \"\"\"\n",
    "    # Check if site_name_id and node_id valid\n",
    "    try:\n",
    "        site_id = site_info_check(site_name_id, node_id)\n",
    "    except ValueError as err:\n",
    "        print(\"Could not query data from level_1 table because of wrong site name/id or node id!\")\n",
    "        return None\n",
    "    \n",
    "    # Define all queries in this database\n",
    "    level0_column_name_query = (\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS\" +\n",
    "                                \" WHERE TABLE_NAME='level_1'\")\n",
    "\n",
    "    # Check if field is specified\n",
    "    if field is None:\n",
    "        level1_data_query = (\"SELECT * FROM level_1 WHERE site_id = %s AND node_id = %s \"\n",
    "                             \"AND datetime >= %s AND datetime <= %s\")\n",
    "    else:\n",
    "        query_string = \"SELECT \" + field + \" FROM level_1 WHERE site_id = %s and node_id = %s \" +\\\n",
    "                       \"AND datetime >= %s AND datetime <= %s\"\n",
    "        level1_data_query = (query_string)\n",
    "\n",
    "    # Connect to the ar_data database\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "\n",
    "    # Check if fieldname is valid\n",
    "    try:\n",
    "        cursor.execute(level0_column_name_query)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "    rows = cursor.fetchall()\n",
    "    rows = [item[0] for item in rows]\n",
    "    if field is not None and field not in rows:\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        raise ValueError(\"field is not a valid column in the table.\")\n",
    "\n",
    "    # Start querying data points\n",
    "    try:\n",
    "        cursor.execute(level1_data_query, (site_id, node_id, starting_datetime, ending_datetime))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Level_1 data query failed!\")\n",
    "        print(err)\n",
    "    rows = cursor.fetchall()\n",
    "\n",
    "    # Close the cursor and connector\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_data_level0_pd(site_id, node_id, starting_time, ending_time, pool_bool=False):\n",
    "    sql_query = \"SELECT * FROM level_0 WHERE site_id = \" + str(site_id) + \" AND node_id = \" + str(node_id) + \\\n",
    "                \" AND datetime >= '\" + starting_time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"' AND datetime <= '\" + \\\n",
    "                ending_time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"'\"\n",
    "    if pool_bool:\n",
    "        cnx = pool.get_connection()\n",
    "    else:\n",
    "        cnx = mysql.connector.connect(user = \"root\", password = \"root\", database = \"ar_data\")\n",
    "    try:\n",
    "        pd_table = pd.read_sql_query(sql_query, cnx)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(\"Querying error happens between pandas and mysql when getting level_1 data.\")\n",
    "    cnx.close()\n",
    "    return pd_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def query_data_level1_pd(site_id, node_id, starting_time, ending_time, pool_bool=False):\n",
    "    sql_query = \"SELECT * FROM level_1 WHERE site_id = \" + str(site_id) + \" AND node_id = \" + str(node_id) + \\\n",
    "                \" AND datetime >= '\" + starting_time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"' AND datetime <= '\" + \\\n",
    "                ending_time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"'\"\n",
    "    if pool_bool:\n",
    "        cnx = pool.get_connection()\n",
    "    else:\n",
    "        cnx = mysql.connector.connect(user = \"root\", password = \"root\", database = \"ar_data\")\n",
    "    try:\n",
    "        pd_table = pd.read_sql_query(sql_query, cnx)\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "        print(\"Querying error happens between pandas and mysql when getting level_1 data.\")\n",
    "    cnx.close()\n",
    "    return pd_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_pd_to_tuple(df_row, col_names):\n",
    "    new_row = ()\n",
    "    for col_name in col_names:\n",
    "        if col_name == 'site_id' or col_name == 'node_id' or col_name == 'sd_card':\n",
    "            item = df_row[col_name].as_matrix()[0]\n",
    "            if item is not None:\n",
    "                item = int(df_row[col_name].as_matrix()[0])\n",
    "        elif col_name == 'datetime':\n",
    "            item = datetime.utcfromtimestamp(df_row[col_name].as_matrix()[0].astype('O')/1e9)\n",
    "        elif col_name == 'unname_1' or col_name == 'unname_2':\n",
    "            continue\n",
    "        else:\n",
    "            item = df_row[col_name].as_matrix()[0]\n",
    "            if item is not None and np.isfinite(item):\n",
    "                item = float(df_row[col_name].as_matrix()[0])\n",
    "            elif item is not None and np.isnan(item):\n",
    "                item = None\n",
    "        new_row += (item, )\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def level0_to_level1_data_merge(site_name, node_id, datetime_range_interupt=None):\n",
    "    site_id, starting_datetime, ending_datetime = level0_to_level1_time(site_name, node_id) \n",
    "    if site_id is None and starting_datetime is None and ending_datetime is None:\n",
    "        return\n",
    "    if datetime_range_interupt is not None:\n",
    "        starting_datetime = datetime_range_interupt[0]\n",
    "        ending_datetime = datetime_range_interupt[1]\n",
    "    datetime_list = []\n",
    "    temp = starting_datetime\n",
    "    new_sd_level_1 = None\n",
    "    new_server_level_1 = None\n",
    "    while temp < ending_datetime:\n",
    "        datetime_list.append(temp)\n",
    "        temp += timedelta(minutes = 15)\n",
    "    \n",
    "    output = ()\n",
    "    level0_pd = query_data_level0_pd(site_id, node_id, starting_datetime, ending_datetime)\n",
    "    level1_pd = query_data_level1_pd(site_id, node_id, starting_datetime, ending_datetime)\n",
    "    col_names = list(level0_pd.columns.values)\n",
    "    \n",
    "    for temp_datetime in datetime_list:\n",
    "        level_0_data_temp = level0_pd.loc[level0_pd['datetime']==temp_datetime].reset_index(drop=True)\n",
    "        level_0_data_temp_length = len(level_0_data_temp)\n",
    "        level_1_data_temp = level1_pd.loc[level1_pd['datetime']==temp_datetime].reset_index(drop=True)\n",
    "        level_1_data_temp_length = len(level_1_data_temp)\n",
    "        \n",
    "        if level_0_data_temp_length == 0:\n",
    "            if level_1_data_temp_length == 1:\n",
    "                continue\n",
    "            elif level_1_data_temp_length == 0:\n",
    "                output = output + ((site_id, node_id, temp_datetime, None, None, None, None, \n",
    "                                    None, None, None, None, None, None, None, None, None, None), )\n",
    "        elif level_0_data_temp_length == 1:\n",
    "            if level_1_data_temp_length == 1:\n",
    "                tuple_insert = convert_pd_to_tuple(level_0_data_temp, col_names)\n",
    "                update_data_level1(site_id, node_id, temp_datetime, tuple_insert)\n",
    "            elif level_1_data_temp_length == 0:\n",
    "                tuple_insert = convert_pd_to_tuple(level_0_data_temp, col_names)\n",
    "                output = output + (tuple_insert, )\n",
    "            if level_0_data_temp['sd_card'].as_matrix()[0] == 0:\n",
    "                new_server_level_1 = temp_datetime\n",
    "            else:\n",
    "                new_sd_level_1 = temp_datetime\n",
    "        elif level_0_data_temp_length >= 2:\n",
    "            if level_1_data_temp_length == 1:\n",
    "                updated = False\n",
    "                for i in range(0, level_0_data_temp_length): \n",
    "                    if level_0_data_temp.loc[i, 'sd_card'] == 1:\n",
    "                        tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[i]], col_names)\n",
    "                        update_data_level1(site_id, node_id, temp_datetime, tuple_insert)\n",
    "                        updated = True\n",
    "                        new_sd_level_1 = temp_datetime\n",
    "                        break\n",
    "                if not updated:\n",
    "                    tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[0]], col_names)\n",
    "                    update_data_level1(site_id, node_id, temp_datetime, tuple_insert)\n",
    "                    new_server_level_1 = temp_datetime\n",
    "            elif level_1_data_temp_length == 0:\n",
    "                inserted = False\n",
    "                for i in range(0, level_0_data_temp_length): \n",
    "                    if level_0_data_temp.loc[i, 'sd_card'] == 1:\n",
    "                        tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[i]], col_names)\n",
    "                        output = output + (tuple_insert, )\n",
    "                        inserted = True\n",
    "                        new_sd_level_1 = temp_datetime\n",
    "                        break\n",
    "                if not inserted:\n",
    "                    tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[0]], col_names)\n",
    "                    output = output + (tuple_insert, )\n",
    "                    new_server_level_1 = temp_datetime\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    if output == ():\n",
    "        print(site_name, node_id, \"Level_1 data table updated from level_0 table!\")\n",
    "        if datetime_range_interupt is None:\n",
    "            try:\n",
    "                if new_server_level_1 is not None:\n",
    "                    cursor.execute(level1_server_time_update, (new_server_level_1, site_id, node_id))\n",
    "                if new_sd_level_1 is not None:\n",
    "                    cursor.execute(level1_sd_time_update, (new_sd_level_1, site_id, node_id))\n",
    "                cnx.commit()\n",
    "            except mysql.connector.Error as err:\n",
    "                print(err)\n",
    "                print(site_name, node_id, \"Updating time error!\")\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return\n",
    "    else:\n",
    "        try:\n",
    "            cursor.executemany(level1_insert_string, output)\n",
    "            cnx.commit()\n",
    "            print(site_name, node_id, \"Level_1 data table updated from level_0 table!\")\n",
    "        except mysql.connector.Error as err:\n",
    "            print(err)\n",
    "            print(site_name, node_id, \"Inserting data into level_1 table failed.\")\n",
    "        if datetime_range_interupt is None:\n",
    "            try:\n",
    "                if new_server_level_1 is not None:\n",
    "                    cursor.execute(level1_server_time_update, (new_server_level_1, site_id, node_id))\n",
    "                if new_sd_level_1 is not None:\n",
    "                    cursor.execute(level1_sd_time_update, (new_sd_level_1, site_id, node_id))\n",
    "                cnx.commit()\n",
    "            except mysql.connector.Error as err:\n",
    "                print(err)\n",
    "                print(site_name, node_id, \"Updating time error!\")\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def level0_to_level1_data_merge_interupt(datetime_range_interupt, site_name=\"Alpha\", node_id=1):\n",
    "    site_id, starting_datetime, ending_datetime = level0_to_level1_time(site_name, node_id, pool_bool = True) \n",
    "    if site_id is None and starting_datetime is None and ending_datetime is None:\n",
    "        return\n",
    "    if datetime_range_interupt is not None:\n",
    "        starting_datetime = datetime_range_interupt[0]\n",
    "        ending_datetime = datetime_range_interupt[1]\n",
    "    datetime_list = []\n",
    "    temp = starting_datetime\n",
    "    new_sd_level_1 = None\n",
    "    new_server_level_1 = None\n",
    "    while temp < ending_datetime:\n",
    "        datetime_list.append(temp)\n",
    "        temp += timedelta(minutes = 15)\n",
    "    \n",
    "    output = ()\n",
    "    level0_pd = query_data_level0_pd(site_id, node_id, starting_datetime, ending_datetime, pool_bool = True)\n",
    "    level1_pd = query_data_level1_pd(site_id, node_id, starting_datetime, ending_datetime, pool_bool = True)\n",
    "    col_names = list(level0_pd.columns.values)\n",
    "    \n",
    "    for temp_datetime in datetime_list:\n",
    "        level_0_data_temp = level0_pd.loc[level0_pd['datetime']==temp_datetime].reset_index(drop=True)\n",
    "        level_0_data_temp_length = len(level_0_data_temp)\n",
    "        level_1_data_temp = level1_pd.loc[level1_pd['datetime']==temp_datetime].reset_index(drop=True)\n",
    "        level_1_data_temp_length = len(level_1_data_temp)\n",
    "        \n",
    "        if level_0_data_temp_length == 0:\n",
    "            if level_1_data_temp_length == 1:\n",
    "                continue\n",
    "            elif level_1_data_temp_length == 0:\n",
    "                output = output + ((site_id, node_id, temp_datetime, None, None, None, None, \n",
    "                                    None, None, None, None, None, None, None, None, None, None), )\n",
    "        elif level_0_data_temp_length == 1:\n",
    "            if level_1_data_temp_length == 1:\n",
    "                tuple_insert = convert_pd_to_tuple(level_0_data_temp, col_names)\n",
    "                update_data_level1(site_id, node_id, temp_datetime, tuple_insert, pool_bool = True)\n",
    "            elif level_1_data_temp_length == 0:\n",
    "                tuple_insert = convert_pd_to_tuple(level_0_data_temp, col_names)\n",
    "                output = output + (tuple_insert, )\n",
    "            if level_0_data_temp['sd_card'].as_matrix()[0] == 0:\n",
    "                new_server_level_1 = temp_datetime\n",
    "            else:\n",
    "                new_sd_level_1 = temp_datetime\n",
    "        elif level_0_data_temp_length >= 2:\n",
    "            if level_1_data_temp_length == 1:\n",
    "                updated = False\n",
    "                for i in range(0, level_0_data_temp_length): \n",
    "                    if level_0_data_temp.loc[i, 'sd_card'] == 1:\n",
    "                        tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[i]], col_names)\n",
    "                        update_data_level1(site_id, node_id, temp_datetime, tuple_insert, pool_bool = True)\n",
    "                        updated = True\n",
    "                        new_sd_level_1 = temp_datetime\n",
    "                        break\n",
    "                if not updated:\n",
    "                    tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[0]], col_names)\n",
    "                    update_data_level1(site_id, node_id, temp_datetime, tuple_insert, pool_bool = True)\n",
    "                    new_server_level_1 = temp_datetime\n",
    "            elif level_1_data_temp_length == 0:\n",
    "                inserted = False\n",
    "                for i in range(0, level_0_data_temp_length): \n",
    "                    if level_0_data_temp.loc[i, 'sd_card'] == 1:\n",
    "                        tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[i]], col_names)\n",
    "                        output = output + (tuple_insert, )\n",
    "                        inserted = True\n",
    "                        new_sd_level_1 = temp_datetime\n",
    "                        break\n",
    "                if not inserted:\n",
    "                    tuple_insert = convert_pd_to_tuple(level_0_data_temp.iloc[[0]], col_names)\n",
    "                    output = output + (tuple_insert, )\n",
    "                    new_server_level_1 = temp_datetime\n",
    "    cnx = pool.get_connection()\n",
    "    cursor = cnx.cursor()\n",
    "    if output == ():\n",
    "        print(site_name, node_id, \"Level_1 data table updated from level_0 table!\")\n",
    "        if datetime_range_interupt is None:\n",
    "            try:\n",
    "                if new_server_level_1 is not None:\n",
    "                    cursor.execute(level1_server_time_update, (new_server_level_1, site_id, node_id))\n",
    "                if new_sd_level_1 is not None:\n",
    "                    cursor.execute(level1_sd_time_update, (new_sd_level_1, site_id, node_id))\n",
    "                cnx.commit()\n",
    "            except mysql.connector.Error as err:\n",
    "                print(err)\n",
    "                print(site_name, node_id, \"Updating time error!\")\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return\n",
    "    else:\n",
    "        try:\n",
    "            cursor.executemany(level1_insert_string, output)\n",
    "            cnx.commit()\n",
    "            print(site_name, node_id, \"Level_1 data table updated from level_0 table!\")\n",
    "        except mysql.connector.Error as err:\n",
    "            print(err)\n",
    "            print(site_name, node_id, \"Inserting data into level_1 table failed.\")\n",
    "        if datetime_range_interupt is None:\n",
    "            try:\n",
    "                if new_server_level_1 is not None:\n",
    "                    cursor.execute(level1_server_time_update, (new_server_level_1, site_id, node_id))\n",
    "                if new_sd_level_1 is not None:\n",
    "                    cursor.execute(level1_sd_time_update, (new_sd_level_1, site_id, node_id))\n",
    "                cnx.commit()\n",
    "            except mysql.connector.Error as err:\n",
    "                print(err)\n",
    "                print(site_name, node_id, \"Updating time error!\")\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global pool\n",
    "    dbconfig = {\n",
    "        \"database\": \"ar_data\",\n",
    "        \"user\": \"root\",\n",
    "        \"password\": \"root\"\n",
    "    }\n",
    "    pool = MySQLConnectionPool(pool_name = \"para_pool\", pool_size = 9, **dbconfig)\n",
    "\n",
    "\n",
    "# Used for updating data longer than 1 month\n",
    "def level0_to_level1_longterm(site_name, node_id, datetime_range):\n",
    "    starting_datetime = datetime_range[0]\n",
    "    ending_datetime = datetime_range[1]\n",
    "    datetime_range_list = []\n",
    "    while starting_datetime < ending_datetime:\n",
    "        datetime_range_list.append((starting_datetime, starting_datetime + timedelta(days=7)))\n",
    "        starting_datetime += timedelta(days=7)\n",
    "    partial_level0_to_level1_merger = partial(level0_to_level1_data_merge_interupt, \n",
    "                                              site_name=site_name, \n",
    "                                              node_id=node_id)\n",
    "    pool_worker = Pool(processes=7, initializer=init)\n",
    "    pool_worker.map(partial_level0_to_level1_merger, datetime_range_list)\n",
    "    pool_worker.close()\n",
    "    pool_worker.join()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
