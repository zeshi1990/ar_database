{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, date\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This script is for initialize the database.\n",
    "def init_db():\n",
    "    DB_NAME = 'ar_data'\n",
    "\n",
    "    TABLES = {}\n",
    "\n",
    "    TABLES['sites'] = (\n",
    "        \"CREATE TABLE `sites` (\"\n",
    "        \"  `site_id` int NOT NULL AUTO_INCREMENT,\"\n",
    "        \"  `site_name` varchar(14) NOT NULL,\"\n",
    "        \"  `num_of_nodes` int NOT NULL,\"\n",
    "        \"  PRIMARY KEY (`site_id`)\"\n",
    "        \") ENGINE=InnoDB\")\n",
    "\n",
    "    \n",
    "    TABLES['motes'] = (\n",
    "        \"CREATE TABLE `motes` (\"\n",
    "        \"  `mote_id` int(3) NOT NULL AUTO_INCREMENT,\"\n",
    "        \"  `site_id` int(2) NOT NULL,\"\n",
    "        \"  `node_id` int(2) NOT NULL,\"\n",
    "        \"  `lat` float NOT NULL,\"\n",
    "        \"  `lon` float NOT NULL,\"\n",
    "        \"  `elevation` float NOT NULL,\"\n",
    "        \"  `put_time` date NOT NULL,\"\n",
    "        \"  `mac` varchar(14) NOT NULL,\"\n",
    "        \"  `sd_last_update` datetime,\"\n",
    "        \"  `server_last_update` datetime,\"\n",
    "        \"  `sd_level_1` datetime NOT NULL,\"\n",
    "        \"  `server_level_1 datetime` datetime NOT NULL,\"\n",
    "        \"  `ground_dist` float,\"\n",
    "        \"  PRIMARY KEY (`site_id`,`node_id`), UNIQUE KEY `mote_id` (`mote_id`)\"\n",
    "        \") ENGINE=InnoDB\")\n",
    "\n",
    "    cnx = mysql.connector.connect(user='root', password='root')\n",
    "    cursor = cnx.cursor()\n",
    "\n",
    "    # Create the database\n",
    "    def create_database(cursor):\n",
    "        try:\n",
    "            cursor.execute(\n",
    "                \"CREATE DATABASE {} DEFAULT CHARACTER SET 'utf8'\".format(DB_NAME))\n",
    "        except mysql.connector.Error as err:\n",
    "            print(\"Failed creating database: {}\".format(err))\n",
    "            exit(1)\n",
    "\n",
    "    try:\n",
    "        cnx.database = DB_NAME    \n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "            create_database(cursor)\n",
    "            cnx.database = DB_NAME\n",
    "        else:\n",
    "            print(err)\n",
    "            exit(1)\n",
    "\n",
    "    # Create two Tables, sites and motes\n",
    "    for name, ddl in TABLES.iteritems():\n",
    "        try:\n",
    "            print(\"Creating table {}: \".format(name), end='')\n",
    "            cursor.execute(ddl)\n",
    "        except mysql.connector.Error as err:\n",
    "            if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "                print(\"already exists.\")\n",
    "            else:\n",
    "                print(err.msg)\n",
    "        else:\n",
    "            print(\"OK\")\n",
    "\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "\n",
    "    # Popoluate sites into the sites table\n",
    "    site_info = pd.read_csv(\"data/site_node_info.csv\", header=0, sep=\",\")\n",
    "    site_names = np.unique(site_info[\"site_id\"].as_matrix())\n",
    "    sites = ()\n",
    "    for site_name in site_names:\n",
    "        temp_site = (site_name, )\n",
    "        sites = sites + (temp_site,)\n",
    "\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database=\"ar_data\")\n",
    "    cursor = cnx.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE sites AUTO_INCREMENT = 1\")\n",
    "        add_site = (\"INSERT INTO sites \"\n",
    "                    \"(site_name) \"\n",
    "                    \"VALUES (%s)\")\n",
    "        cursor.executemany(add_site, sites)\n",
    "        cnx.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Failed populating data into motes: {}\".format(err))\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "\n",
    "    # Populate motes into the sites table\n",
    "    motes = ()\n",
    "    query = (\"SELECT site_id FROM sites WHERE site_name = %s\")\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    try:\n",
    "        for idx, row in site_info.iterrows():\n",
    "            site_name = (row[\"site_id\"],)\n",
    "            cursor.execute(query, site_name)\n",
    "            site_id = cursor.fetchone()\n",
    "            if site_id:\n",
    "                temp_motes = (site_id[0], )\n",
    "                temp_motes = temp_motes + (row[\"node_id\"], \n",
    "                                           row[\"lat\"], \n",
    "                                           row[\"long\"], \n",
    "                                           row[\"elev\"], \n",
    "                                           datetime.now().strftime(\"%Y-%m-%d\"), row[\"mac\"])\n",
    "                motes = motes + (temp_motes,)\n",
    "            else:\n",
    "                print(\"The site name of \" + site_name + \" does not exist!\")\n",
    "    except mysql.connector.Error as err:\n",
    "            print(\"Failed querying data from sites: {}\".format(err))\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database=\"ar_data\")\n",
    "    cursor = cnx.cursor()\n",
    "    try:\n",
    "        cursor.execute(\"ALTER TABLE motes AUTO_INCREMENT = 1\")\n",
    "        add_mote = (\"INSERT INTO motes \"\n",
    "                    \"(site_id, node_id, lat, lon, elevation, put_time, mac) \"\n",
    "                    \"VALUES (%s, %s, %s, %s, %s, %s, %s)\")\n",
    "        cursor.executemany(add_mote, motes)\n",
    "        cnx.commit()\n",
    "    except mysql.connector.Error as err:\n",
    "            print(\"Failed populating data into motes: {}\".format(err))\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "    \n",
    "    # Create a table called level_0, which is used to store all parsed level_0 data\n",
    "    TABLE_ts = (\n",
    "        \"CREATE TABLE `level_0` (\"\n",
    "        \"  `site_id` int NOT NULL,\"\n",
    "        \"  `node_id` int NOT NULL,\"\n",
    "        \"  `datetime` datetime NOT NULL,\"\n",
    "        \"  `voltage` float,\"\n",
    "        \"  `temperature_temprh` float,\"\n",
    "        \"  `relative_humidity` float,\"\n",
    "        \"  `soil_moisture_1` float,\"\n",
    "        \"  `soil_temperature_1` float,\"\n",
    "        \"  `soil_ec_1` float,\"\n",
    "        \"  `soil_moisture_2` float,\"\n",
    "        \"  `soil_temperature_2` float,\"\n",
    "        \"  `soil_ec_2` float,\"\n",
    "        \"  `snowdepth` float,\"\n",
    "        \"  `judd_temp` float,\"\n",
    "        \"  `unname_1` float,\"\n",
    "        \"  `unname_2` float,\"\n",
    "        \"  `solar` float,\"\n",
    "        \"  `maxibotics` float,\"\n",
    "        \"  `sd_card` tinyint(1),\"\n",
    "        \"  FOREIGN KEY (`site_id`, `node_id`) REFERENCES motes(`site_id`, `node_id`),\"\n",
    "        \"  KEY (`datetime`)\"\n",
    "        \") ENGINE=InnoDB\")\n",
    "\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    try:\n",
    "        print(\"Creating table {}: \".format('level_0'), end='')\n",
    "        cursor.execute(TABLE_ts)\n",
    "    except mysql.connector.Error as err:\n",
    "        if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(\"already exists.\")\n",
    "        else:\n",
    "            print(err.msg)\n",
    "    else:\n",
    "        print(\"OK\")\n",
    "\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function below should read and parse server data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_server_file(fn, site_id, node_id, server_last_update):\n",
    "    # Read the file\n",
    "    f = open(fn, \"r\")\n",
    "    \n",
    "    # initialize the mode of the data as 12\n",
    "    mode = 14\n",
    "    \n",
    "    # initialize the output of the data\n",
    "    output = ()\n",
    "    new_server_last_update = server_last_update\n",
    "    old_line = \"~~~\"\n",
    "    # Start processing each line of the data from the bottom of the file\n",
    "    for line in reversed(list(f)):\n",
    "\n",
    "        # Filter out the row starting with \"~\" \n",
    "        # this line of data is just recording the meta information of the node\n",
    "        if line[0] == \"~\":\n",
    "            old_line = line\n",
    "            continue\n",
    "\n",
    "        else:\n",
    "            line_list = line.split(\",\")\n",
    "            length_new = len(line_list)\n",
    "            # Only use the rows whose length is larger or equal to 10\n",
    "            if length_new >= 10:\n",
    "\n",
    "                # Some data starting with the mode of 14, detect them, if they change to 14\n",
    "                # keep using them\n",
    "                if length_new == 12 and mode == 14 and old_line[0] == \"~\":\n",
    "                    mode = 12\n",
    "                # Try split the data string and parse the first two items\n",
    "                # If failed, continue to the next row of data\n",
    "                try:\n",
    "                    time_str = line_list[0].split(\":\")\n",
    "                    date_str = line_list[1].split(\"/\")\n",
    "                    line_datetime = datetime(int(date_str[2]), int(date_str[0]), int(date_str[1]),\n",
    "                                        int(time_str[0]), int(time_str[1], int(time_str[2])))\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                # If the time stamp is larger than now, continue to the next row of data\n",
    "                if line_datetime > datetime.now() or line_datetime < datetime(2013, 1, 1):\n",
    "                    continue\n",
    "                    \n",
    "                # If the time stamp is smaller or equal than the last update time\n",
    "                if server_last_update and line_datetime <= server_last_update:\n",
    "                    break\n",
    "                \n",
    "                # If line_datetime is larger than the last time update the db, record new last update time\n",
    "                if (new_server_last_update is None) or (line_datetime > new_server_last_update):\n",
    "                    new_server_last_update = line_datetime\n",
    "                \n",
    "                temp_line = (site_id, node_id, line_datetime)\n",
    "                \n",
    "                # Voltage, temperature, relative_humidity, soil moisture temperature ec #12, index 2 - 10\n",
    "                for idx in range(2, 11):\n",
    "                    try:\n",
    "                        if float(line_list[idx]) != float('Inf'):\n",
    "                            temp_line += (float(line_list[idx]), )\n",
    "                        else:\n",
    "                            temp_line += (None, )\n",
    "                    except:\n",
    "                        temp_line += (None, )\n",
    "                if mode == 12:\n",
    "                    # Snow depth\n",
    "                    try:\n",
    "                        if float(line_list[-1]) != float('Inf'):\n",
    "                            temp_line += (float(line_list[-1]), )\n",
    "                        else:\n",
    "                            temp_line += (None, )\n",
    "                    except:\n",
    "                        temp_line += (None, )\n",
    "                        \n",
    "                    # Solar radiation\n",
    "                    temp_line += (None, )\n",
    "                    \n",
    "                    # For caples, need to add maxibotics\n",
    "                    if site_id == 3:\n",
    "                        temp_line += (None, )\n",
    "                    \n",
    "                else:\n",
    "                    # Snow depth\n",
    "                    try:\n",
    "                        if float(line_list[-2]) != float('Inf'):\n",
    "                            temp_line += (float(line_list[-2]), )\n",
    "                        else:\n",
    "                            temp_line += (None, )\n",
    "                    except:\n",
    "                        temp_line += (None, )\n",
    "                    \n",
    "                    # Solar radiation\n",
    "                    try:\n",
    "                        if float(line_list[-1]) != float('Inf'):\n",
    "                            temp_line += (float(line_list[-1]), )\n",
    "                        else:\n",
    "                            temp_line += (None, )\n",
    "                    except:\n",
    "                        temp_line += (None, )\n",
    "                    \n",
    "                    # For caples, need to add maxibotics\n",
    "                    if site_id == 3:\n",
    "                        try:\n",
    "                            if float(line_list[-3]) != float('Inf'):\n",
    "                                temp_line += (float(line_list[-3]), )\n",
    "                            else:\n",
    "                                temp_line += (None, )\n",
    "                        except:\n",
    "                            temp_line += (None, )\n",
    "                    \n",
    "                temp_line += (0, )\n",
    "                output = (temp_line, ) + output\n",
    "            old_line = line\n",
    "    if output == ():\n",
    "        return None\n",
    "    else:\n",
    "        return (output, new_server_last_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function below populate data from the folder having all server data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def populate_data_server(site_name):\n",
    "    print(\"Start populating server data into mysql at \"+site_name)\n",
    "    files = os.listdir(\"server_data/\"+site_name)\n",
    "    if \".DS_Store\" in files:\n",
    "        files.remove(\".DS_Store\")\n",
    "    node_query = (\"SELECT site_id, node_id, put_time, server_last_update FROM motes WHERE mac = %s\")\n",
    "    site_name_query = (\"SELECT site_name FROM sites WHERE site_id = %s\")\n",
    "    update_table_motes = (\"UPDATE motes SET server_last_update = %s WHERE site_id = %s AND node_id = %s AND mac = %s\")\n",
    "    insert_table_level_0 = (\"INSERT INTO level_0 \"\n",
    "                            \"(site_id, node_id, datetime, voltage, temperature, relative_humidity, \"\n",
    "                            \"soil_moisture_1, soil_temperature_1, soil_ec_1, soil_moisture_2, \"\n",
    "                            \"soil_temperature_2, soil_ec_2, snowdepth, solar, sd_card) \"\n",
    "                            \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "    insert_table_level_0_caples = (\"INSERT INTO level_0 \"\n",
    "                            \"(site_id, node_id, datetime, voltage, temperature, relative_humidity, \"\n",
    "                            \"soil_moisture_1, soil_temperature_1, soil_ec_1, soil_moisture_2, \"\n",
    "                            \"soil_temperature_2, soil_ec_2, snowdepth, solar, maxibotics, sd_card) \"\n",
    "                            \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    for f in files:\n",
    "        mac = f[:-4].split(\"_\")\n",
    "        mac = mac[-3] + mac[-2] + mac[-1]\n",
    "        print(site_name + \": \" + mac)\n",
    "        try:\n",
    "            cursor.execute(node_query, (mac,))\n",
    "        except mysql.connector.Error as err:\n",
    "            print(\"Querying error happens when trying to query mac address \" + f)\n",
    "            print(err)\n",
    "            continue\n",
    "        \n",
    "        rows = cursor.fetchall()\n",
    "        if cursor.rowcount == 0:\n",
    "            print(\"No node found to mac address: \" + mac + site_name)\n",
    "            continue\n",
    "        max_row = rows[0]\n",
    "        if len(rows) > 1:\n",
    "            for row in rows[1:]:\n",
    "                if row[2] > max_row[2]:\n",
    "                    max_row = row\n",
    "        site_id = max_row[0]\n",
    "        node_id = max_row[1]\n",
    "        server_last_update = max_row[3]\n",
    "        try:\n",
    "            cursor.execute(site_name_query, (site_id, ))\n",
    "        except mysql.connector.Error as err:\n",
    "            print(\"Querying error happens when trying to query site id \" + str(site_id))\n",
    "            print(err)\n",
    "            continue \n",
    "        db_site_name = cursor.fetchone()[0]\n",
    "        if db_site_name != site_name:\n",
    "            print(\"The neomote with mac adress: \" + mac + \"has been swapped to another site.\")\n",
    "            continue\n",
    "        fn = \"server_data/\" + site_name + \"/\" + f\n",
    "        new_items = parse_server_file(fn, site_id, node_id, server_last_update)\n",
    "        if new_items:\n",
    "            update_data = new_items[0]\n",
    "            new_server_last_update = new_items[1]\n",
    "            try:\n",
    "                cursor.execute(update_table_motes, (new_server_last_update, site_id, node_id, mac))\n",
    "                if site_name != \"caples_lk\":\n",
    "                    cursor.executemany(insert_table_level_0, update_data)\n",
    "                else:\n",
    "                    cursor.executemany(insert_table_level_0_caples, update_data)\n",
    "                cnx.commit()\n",
    "            except mysql.connector.Error as err:\n",
    "                print(\"Error happens when inserting data!\")\n",
    "                print(err)\n",
    "                print(update_data)\n",
    "                break\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The function below should read and parse the SD card data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_sd_file(fn, site_id, node_id, sd_last_update):\n",
    "    # Read the file\n",
    "    f = open(fn, \"r\")\n",
    "    \n",
    "    # initialize the mode of the data as 12\n",
    "    mode = 17\n",
    "    \n",
    "    # initialize the output of the data\n",
    "    output = ()\n",
    "    new_sd_last_update = sd_last_update\n",
    "    # Start processing each line of the data from the bottom of the file\n",
    "    for line in reversed(list(f)):\n",
    "        line_list = line.split(\",\")\n",
    "        length_new = len(line_list)\n",
    "        # Only use the rows whose length is larger or equal to 10\n",
    "        if length_new == 15 or length_new == 17:\n",
    "\n",
    "            # Some data starting with the mode of 14, detect them, if they change to 14\n",
    "            # keep using them\n",
    "            if length_new == 15 and mode == 17 :\n",
    "                mode = 15\n",
    "\n",
    "            # Try split the data string and parse the first two items\n",
    "            # If failed, continue to the next row of data\n",
    "            try:\n",
    "                time_str = line_list[0].split(\":\")\n",
    "                date_str = line_list[1].split(\"/\")\n",
    "                line_datetime = datetime(int(date_str[2]), int(date_str[0]), int(date_str[1]),\n",
    "                                    int(time_str[0]), int(time_str[1], int(time_str[2])))\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # If the time stamp is larger than now, continue to the next row of data\n",
    "            if line_datetime > datetime.now() or line_datetime < datetime(2013, 1, 1):\n",
    "                continue\n",
    "\n",
    "            # If the time stamp is smaller or equal than the last update time\n",
    "            if sd_last_update and line_datetime <= sd_last_update:\n",
    "                break\n",
    "\n",
    "            # If line_datetime is larger than the last time update the db, record new last update time\n",
    "            if (new_sd_last_update is None) or (line_datetime > new_sd_last_update):\n",
    "                new_sd_last_update = line_datetime\n",
    "\n",
    "            temp_line = (site_id, node_id, line_datetime)\n",
    "\n",
    "            # Voltage, temperature, relative_humidity, soil moisture temperature ec #12, index 2 - 10\n",
    "            for idx in range(2, 11):\n",
    "                try:\n",
    "                    if float(line_list[idx]) == -99.:\n",
    "                        temp_line += (None, )\n",
    "                    else:\n",
    "                        temp_line += (float(line_list[idx]), )\n",
    "                except:\n",
    "                    temp_line += (None, )\n",
    "            \n",
    "            # Snow depth\n",
    "            try:\n",
    "                temp_line += (float(line_list[11]), )\n",
    "            except:\n",
    "                temp_line += (None, )\n",
    "                \n",
    "            # Judd temp\n",
    "            try:\n",
    "                temp_line += (float(line_list[12]), )\n",
    "            except:\n",
    "                temp_line += (None, )\n",
    "                \n",
    "            # Unname_1\n",
    "            try:\n",
    "                temp_line += (float(line_list[13]), )\n",
    "            except:\n",
    "                temp_line += (None, )\n",
    "                \n",
    "            # Unname_2\n",
    "            try:\n",
    "                temp_line += (float(line_list[14]), )\n",
    "            except:\n",
    "                temp_line += (None, )\n",
    "\n",
    "            if mode == 15:\n",
    "                # Solar radiation\n",
    "                temp_line += (None, )\n",
    "                # Maxibotics\n",
    "                temp_line += (None, )\n",
    "            \n",
    "            if mode == 17:\n",
    "                # Solar radiation\n",
    "                try:\n",
    "                    temp_line += (float(line_list[15]), )\n",
    "                except:\n",
    "                    temp_line += (None, )\n",
    "\n",
    "                # Maxibotics\n",
    "                try:\n",
    "                    temp_line += (float(line_list[16]), )\n",
    "                except:\n",
    "                    temp_line += (None, )\n",
    "\n",
    "            temp_line += (1, )\n",
    "            output = (temp_line, ) + output\n",
    "    if output == ():\n",
    "        return None\n",
    "    else:\n",
    "        return (output, new_sd_last_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def populate_data_sd(site_name):\n",
    "    print(\"Start populating SD card data into mysql at \"+site_name)\n",
    "    files = os.listdir(\"sd_data/\"+site_name) # Need to change the folder name in real application\n",
    "    if \".DS_Store\" in files:\n",
    "        files.remove(\".DS_Store\")\n",
    "    site_id_query = (\"SELECT site_id FROM sites WHERE site_name = %s\")\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    cursor.execute(site_id_query, (site_name, ))\n",
    "    site_id = cursor.fetchall()[0][0]\n",
    "    if cursor.rowcount == 0:\n",
    "        print(\"No site was found to site name:\" + site_name)\n",
    "        cursor.close()\n",
    "        cnx.close()\n",
    "        return\n",
    "    node_query = (\"SELECT sd_last_update FROM motes WHERE site_id = %s AND node_id = %s\")\n",
    "    update_table_motes = (\"UPDATE motes SET sd_last_update = %s WHERE site_id = %s AND node_id = %s\")\n",
    "    insert_table_level_0 = (\"INSERT INTO level_0 \"\n",
    "                            \"(site_id, node_id, datetime, voltage, temperature, relative_humidity, \"\n",
    "                            \"soil_moisture_1, soil_temperature_1, soil_ec_1, soil_moisture_2, \"\n",
    "                            \"soil_temperature_2, soil_ec_2, snowdepth, judd_temp, unname_1, unname_2, \"\n",
    "                            \"solar, maxibotics, sd_card) \"\n",
    "                            \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "    for f in files:\n",
    "        # parse the file_name\n",
    "        node_num_date = f[(len(site_name)+1):].split(\"_\")\n",
    "        node_id = int(node_num_date[0])\n",
    "        date_str = node_num_date[1][:-4]\n",
    "        node_visit_time = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "        try:\n",
    "            cursor.execute(node_query, (site_id, node_id))\n",
    "        except mysql.connector.Error as err:\n",
    "            print(\"Querying error happens when trying to query time from node id \" + \\\n",
    "                  str(node_id) + \" at site \" + site_name)\n",
    "            print(err)\n",
    "            continue\n",
    "        sd_last_update = cursor.fetchall()[0][0]\n",
    "        \n",
    "        if cursor.rowcount == 0:\n",
    "            print(\"No node found to node id: \" + str(node_id) + \" at site \" + site_name)\n",
    "            continue\n",
    "        \n",
    "        # If the node_visit_time is earlier than sd_last_update we continue over this file\n",
    "        if sd_last_update and (node_visit_time < sd_last_update):\n",
    "            continue\n",
    "        \n",
    "        fn = \"sd_data/\" + site_name + \"/\" + f\n",
    "        new_items = parse_sd_file(fn, site_id, node_id, sd_last_update)\n",
    "        if new_items:\n",
    "            update_data = new_items[0]\n",
    "            new_sd_last_update = new_items[1]\n",
    "            temp_temp = None\n",
    "            try:\n",
    "                cursor.execute(update_table_motes, (new_sd_last_update, site_id, node_id))\n",
    "                cursor.executemany(insert_table_level_0, update_data)\n",
    "                cnx.commit()\n",
    "            except mysql.connector.Error as err:\n",
    "                print(\"Error happens when inserting data!\")\n",
    "                print(temp_temp)\n",
    "                print(err)\n",
    "                break\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start populating SD card data into mysql at Duncan_Pk\n"
     ]
    }
   ],
   "source": [
    "populate_data_sd(\"Duncan_Pk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__The function below allows programmer to query data from the database by__\n",
    "```\n",
    "site_name: string. The name of the site you want to query [Please look up the correct name]\n",
    "node_id: integer. The id of the node in that site\n",
    "starting_date: date.\n",
    "ending_date: date.\n",
    "field: string. The name of the column name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_data_level0(site_name_id, node_id, starting_date, ending_date, field = None):\n",
    "    # Check if site_name_id is site_id or site_name\n",
    "    use_id = False\n",
    "    if isinstance(site_name_id, int):\n",
    "        site_id = site_name_id\n",
    "        use_id = True\n",
    "    if isinstance(site_name_id, str):\n",
    "        site_name = site_name_id\n",
    "    \n",
    "    # Define all queries in this database\n",
    "    site_id_query = (\"SELECT site_id, num_of_nodes FROM sites WHERE site_name = %s\")\n",
    "    site_num_of_nodes_query = (\"SELECT num_of_nodes FROM sites WHERE site_id = %s\")\n",
    "    level0_column_name_query = (\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME='level_0'\")\n",
    "    \n",
    "    # Check if field is specified\n",
    "    if field is None:\n",
    "        level0_data_query = (\"SELECT * FROM level_0 WHERE site_id = %s AND node_id = %s \"\n",
    "                             \"AND datetime >= %s AND datetime <= %s\")\n",
    "    else:\n",
    "        query_string = \"SELECT \" + field + \" FROM level_0 WHERE site_id = %s and node_id = %s \" + \\\n",
    "                       \"AND datetime >= %s AND datetime <= %s\"\n",
    "        level0_data_query = (query_string)\n",
    "    \n",
    "    # Connect to the ar_data database\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    \n",
    "    # Check if site_name is valid\n",
    "    if not use_id:\n",
    "        try:\n",
    "            cursor.execute(site_id_query, (site_name, ))\n",
    "        except mysql.connector.Error as err:\n",
    "            print(err)\n",
    "        rows = cursor.fetchall()\n",
    "        if cursor.rowcount == 0:\n",
    "            raise ValueError(\"site name does not represent a valid site.\")\n",
    "\n",
    "        # Check if node_id is valid\n",
    "        site_id = rows[0][0]\n",
    "        max_num_nodes = rows[0][1]\n",
    "        if node_id > max_num_nodes or node_id <= 0:\n",
    "            raise ValueError(\"node_id does not represent a valid node in this site.\")\n",
    "    \n",
    "    else:\n",
    "        try:\n",
    "            cursor.execute(site_num_of_nodes_query, (site_id, ))\n",
    "        except mysql.connector.Error as err:\n",
    "            print(err)\n",
    "        rows = cursor.fetchall()\n",
    "        if cursor.rowcount == 0:\n",
    "            raise ValueError(\"site id does not represent a valid id.\")\n",
    "        max_num_nodes = rows[0][0]\n",
    "        if node_id > max_num_nodes or node_id <= 0:\n",
    "            raise ValueError(\"node_id does not represent a valid node in this site.\")\n",
    "        \n",
    "    # Check if fieldname is valid\n",
    "    try:\n",
    "        cursor.execute(level0_column_name_query)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "    rows = cursor.fetchall()\n",
    "    rows = [item[0] for item in rows]\n",
    "    if field is not None and field not in rows:\n",
    "        raise ValueError(\"field is not a valid column in the table.\")\n",
    "    \n",
    "    # Formatting start time\n",
    "    starting_datetime = datetime.combine(starting_date, datetime.min.time())\n",
    "    ending_datetime = datetime.combine(ending_date, datetime.max.time())\n",
    "    try:\n",
    "        cursor.execute(level0_data_query, (site_id, node_id, starting_datetime, ending_datetime))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(level0_data_query)\n",
    "        print(err)\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    # Close the cursor and connector\n",
    "    cursor.close()\n",
    "    cnx.close()\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def level0_to_level1(site_name, node_id, starting_time, ending_time):\n",
    "    # Define all queries in this database\n",
    "    site_id_query = (\"SELECT site_id, num_of_nodes FROM sites WHERE site_name = %s\")\n",
    "    level1_time_query = (\"SELECT sd_level1\")\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data')\n",
    "    cursor = cnx.cursor()\n",
    "    # Check if site_name is valid\n",
    "    try:\n",
    "        cursor.execute(site_id_query, (site_name, ))\n",
    "    except mysql.connector.Error as err:\n",
    "        print(err)\n",
    "    rows = cursor.fetchall()\n",
    "    if cursor.rowcount == 0:\n",
    "        raise ValueError(\"site_name does not represent a valid site.\")\n",
    "    \n",
    "    # Check if node_id is valid\n",
    "    site_id = rows[0][0]\n",
    "    max_num_nodes = rows[0][1]\n",
    "    if node_id > max_num_nodes or node_id <= 0:\n",
    "        raise ValueError(\"node_id does not represent a valid node in this site.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This function should be runned every year before the snow season to figure out the baseline of the snow-depth data__\n",
    "```\n",
    "WY: Water year\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def snowdepth_baseline_update(WY):\n",
    "    all_motes_query = (\"SELECT site_id, node_id FROM motes\")\n",
    "    site_name_query = (\"SELECT site_name FROM sites WHERE site_id = %s\")\n",
    "    baseline_update = (\"UPDATE motes SET ground_dist = %s WHERE site_id = %s AND node_id = %s\")\n",
    "#     old_baseline_query = (\"SELECT ground_dist FROM motes WHERE site_id = %s AND node_id = %s\")\n",
    "    min_datetime = datetime(WY-1, 8, 1)\n",
    "    max_datetime = datetime(WY-1, 10, 1)\n",
    "    cnx = mysql.connector.connect(user='root', password='root', database='ar_data') \n",
    "    cursor = cnx.cursor()\n",
    "    try:\n",
    "        cursor.execute(all_motes_query)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Query motes problem\")\n",
    "        print(err)\n",
    "    all_motes = cursor.fetchall()\n",
    "    for mote in all_motes:\n",
    "        mote_ground_distance = query_data_level0(mote[0], mote[1], min_datetime, max_datetime, field='snowdepth')\n",
    "        mote_ground_distance = np.array([i[0] for i in mote_ground_distance])\n",
    "        mote_ground_distance = mote_ground_distance[mote_ground_distance >= 2000.]\n",
    "        ground_distance = np.nanmean(mote_ground_distance)\n",
    "        if mote_ground_distance.size == 0:\n",
    "            ground_distance = None\n",
    "        if ground_distance is not None:\n",
    "            try:\n",
    "                cursor.execute(baseline_update, (float(ground_distance), mote[0], mote[1]))\n",
    "            except mysql.connector.Error as err:\n",
    "                print(err)\n",
    "    cnx.commit()\n",
    "    cursor.close()\n",
    "    cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This is a temporal cell for testing the function I have created\n",
    "\n",
    "#### Below is for populating data into the database\n",
    "# populate_data_server(\"Alpha\")\n",
    "# populate_data_server(\"Bear_Trap\")\n",
    "# populate_data_server(\"Caples_Lk\")\n",
    "# populate_data_server(\"Duncan_Pk\")\n",
    "# populate_data_server(\"Echo_Pk\")\n",
    "# populate_data_server(\"Mt_Lincoln\")\n",
    "# populate_data_server(\"Onion_Ck\")\n",
    "# populate_data_server(\"Robbs_Saddle\")\n",
    "\n",
    "#### Below is for calculating the data\n",
    "# snowdepth_baseline_update(2016)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
