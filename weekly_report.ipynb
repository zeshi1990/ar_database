{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from level1_cleaning import level1_cleaning_site\n",
    "\n",
    "mpl.rc(\"font\", family=\"Helvetica\")\n",
    "mpl.rc(\"font\", size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def init():\n",
    "    global cnx\n",
    "    cnx = mysql.connector.connect(user=\"root\", password=\"root\", database=\"ar_data\")\n",
    "    site_info_query_command = \"SELECT * FROM sites\"\n",
    "    site_table = pd.read_sql_query(site_info_query_command, cnx)\n",
    "    return site_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define week start datetime, this needs to be automated after this report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def node_info_query_by_site(site_table, start_time):\n",
    "    valid_motes = np.empty((0, 4))\n",
    "    for index, site_info in site_table.iterrows():\n",
    "        site_id = site_info['site_id']\n",
    "        site_name = site_info['site_name']\n",
    "        node_info_query_command = \"SELECT node_id, elevation, server_last_update, \" + \\\n",
    "                                  \" sd_last_update, ground_dist FROM motes WHERE site_id = \" + str(site_id)\n",
    "        node_table = pd.read_sql_query(node_info_query_command, cnx)\n",
    "        for node_index, node_info in node_table.iterrows():\n",
    "            node_id = node_info['node_id']\n",
    "            elevation = node_info['elevation']\n",
    "            server_last_update = node_info['server_last_update']\n",
    "            sd_last_update = node_info['sd_last_update']\n",
    "            ground_dist = node_info['ground_dist']\n",
    "            if ground_dist is None:\n",
    "                continue\n",
    "            if server_last_update is None and sd_last_update is None:\n",
    "                continue\n",
    "            if np.isnan(ground_dist):\n",
    "                continue\n",
    "            if server_last_update is None and sd_last_update < start_time:\n",
    "                continue\n",
    "            if sd_last_update is None and server_last_update < start_time:\n",
    "                continue\n",
    "            if sd_last_update is not None and server_last_update is not None:\n",
    "                if sd_last_update < start_time and server_last_update < start_time:\n",
    "                    continue\n",
    "            else:\n",
    "                valid_motes = np.vstack((valid_motes, np.array([site_id, node_id, elevation, ground_dist])))\n",
    "    return valid_motes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_snowdepth(site_table, week_start_time):\n",
    "    for index, site_info in site_table.iterrows():\n",
    "        site_id = site_info['site_id']\n",
    "        for dt in range(0, 7):\n",
    "            temp_datetime = week_start_time + timedelta(days=dt)\n",
    "            print site_id, temp_datetime, \"start to clean\"\n",
    "            level1_cleaning_site(site_id, temp_datetime, temp_datetime + timedelta(days=1))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def query_clean_snowdepth(valid_motes, week_start_time):\n",
    "    week_end_time = week_start_time + timedelta(days=7)\n",
    "    site_id_unique = np.unique(valid_motes[:, 0])\n",
    "    site_sd_info = np.empty((0, 4))\n",
    "    for site_id in site_id_unique:\n",
    "        site_valid_motes = valid_motes[valid_motes[:, 0] == site_id]\n",
    "        site_clean_sd = np.empty((1, 0))\n",
    "        elevation_mean = np.nanmean(site_valid_motes[:, 2])\n",
    "        for mote_info in site_valid_motes:\n",
    "            site_id = int(mote_info[0])\n",
    "            node_id = int(mote_info[1])\n",
    "            elevation = int(mote_info[2])\n",
    "            ground_dist = int(mote_info[3])\n",
    "            query_string = \"SELECT sd_clean FROM level_1 WHERE site_id = \" + str(site_id) + \" AND node_id = \" + str(node_id) + \\\n",
    "                           \" AND datetime <= '\" + week_end_time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"' AND datetime >= '\" + \\\n",
    "                           week_start_time.strftime(\"%Y-%m-%d %H:%M:%S\") + \"'\"\n",
    "            clean_sd = pd.read_sql_query(query_string, cnx).as_matrix()\n",
    "            if clean_sd[0, 0] is None:\n",
    "                continue\n",
    "            clean_sd = ground_dist - clean_sd\n",
    "            site_clean_sd = np.append(site_clean_sd, clean_sd)\n",
    "        sd_mean = np.nanmean(site_clean_sd)\n",
    "        sd_std = np.nanstd(site_clean_sd)\n",
    "        site_sd_info = np.vstack((site_sd_info, np.array([site_id, elevation_mean, sd_mean, sd_std])))\n",
    "    return site_sd_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def datetime_to_string(datetime_datetime):\n",
    "    return \"'\" + datetime_datetime.strftime(\"%Y-%m-%d %H:%M:%S\") + \"'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weekly_avg_std_by_site():\n",
    "    week_start_time = datetime(2016, 3, 22)\n",
    "    site_table = init()\n",
    "    valid_motes = node_info_query_by_site(site_table, week_start_time)\n",
    "    clean_snowdepth(site_table, week_start_time)\n",
    "    site_sd_info = query_clean_snowdepth(valid_motes, week_start_time)\n",
    "    site_sd_info = site_sd_info[~np.isnan(site_sd_info[:, 2])]\n",
    "    site_sd_info = site_sd_info[np.argsort(site_sd_info[:, 1])]\n",
    "    site_name = []\n",
    "    for temp_site_sd_info in site_sd_info:\n",
    "        site_name.append(site_table.loc[site_table['site_id'] == int(temp_site_sd_info[0]), 'site_name'].as_matrix()[0])\n",
    "    x = np.array(range(1, len(site_sd_info)+1))\n",
    "    sd = site_sd_info[:, 2] / 10.\n",
    "    sd_std = site_sd_info[:, 3] / 10.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.xticks(x, site_name)\n",
    "    plt.errorbar(x, sd, yerr=sd_std, fmt='o')\n",
    "    plt.xlim([0, 5])\n",
    "    plt.xlabel(\"Site name, sorted by elevation\")\n",
    "    plt.ylabel(\"Snow depth, cm\")\n",
    "    plt.grid()\n",
    "    plt.savefig(\"week_example.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ts_query_by_site(site_motes, ts_start_time_str, ts_stop_time_str):\n",
    "    sd_matrix = None\n",
    "    for mote in site_motes:\n",
    "        site_id = int(mote[0])\n",
    "        node_id = int(mote[1])\n",
    "        elevation = int(mote[2])\n",
    "        ground_dist = int(mote[3])\n",
    "        query_str = \"SELECT sd_clean FROM level_1 WHERE site_id = \" + str(site_id) + \" AND node_id = \" + str(node_id) + \\\n",
    "                    \" AND datetime <= \" + ts_stop_time_str + \" AND datetime >= \" + ts_start_time_str\n",
    "        clean_sd = pd.read_sql_query(query_str, cnx).as_matrix()\n",
    "        if clean_sd[0, 0] is None:\n",
    "            continue\n",
    "        clean_sd = ground_dist - clean_sd\n",
    "        if sd_matrix is None:\n",
    "            sd_matrix = clean_sd\n",
    "        else:\n",
    "            sd_matrix = np.column_stack((sd_matrix, clean_sd))\n",
    "    return sd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ts_wyd_by_site(site_table):\n",
    "    now = datetime.now()\n",
    "    current_month = now.month\n",
    "    current_year = now.year\n",
    "    if current_month >= 10:\n",
    "        wy = current_year + 1\n",
    "    else:\n",
    "        wy = current_year\n",
    "    ts_start_time = datetime(wy-1, 10, 1)\n",
    "    ts_stop_time = datetime(now.year, now.month, now.day)\n",
    "    ts_start_time_str = datetime_to_string(ts_start_time)\n",
    "    ts_stop_time_str = datetime_to_string(ts_stop_time)\n",
    "    valid_motes = node_info_query_by_site(site_table, ts_start_time)\n",
    "    unique_sites_id = np.unique(valid_motes[:, 0]).astype(int)\n",
    "    fig, axarr = plt.subplots(len(unique_sites_id), sharex=True, figsize=(10, len(unique_sites_id) * 5))\n",
    "    for i, site_id in enumerate(unique_sites_id):\n",
    "        site_motes = valid_motes[valid_motes[:, 0] == site_id]\n",
    "        site_sd_clean = ts_query_by_site(site_motes, ts_start_time_str, ts_stop_time_str)\n",
    "        if site_sd_clean is None:\n",
    "            continue\n",
    "        ts_sd_avg = np.nanmean(site_sd_clean, axis=1)\n",
    "        ts_sd_std = np.nanstd(site_sd_clean, axis=1)\n",
    "        data_length = len(ts_sd_std)\n",
    "        time_list = [ts_start_time + timedelta(minutes=15*j) for j in range(0, data_length)]\n",
    "        axarr[i].plot(time_list, ts_sd_avg)\n",
    "        axarr[i].fill_between(time_list, ts_sd_avg - ts_sd_std, ts_sd_avg + ts_sd_std, facecolor=\"grey\", alpha=0.6)\n",
    "    plt.show()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnx.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
